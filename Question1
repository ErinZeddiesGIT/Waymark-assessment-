#Answer- 1000

import boto3
import pandas as pd
import os

# AWS S3 configuration
bucket_name = 'waymark-assignment'
object_key = 'patient_id_month_year.csv'
aws_access_key_id = 'AKIAZLXG4RYJBLE4OTXT'
aws_secret_access_key = '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'

# Initialize S3 client
s3 = boto3.client('s3', aws_access_key_id=aws_access_key_id, aws_secret_access_key=aws_secret_access_key)

# Fetch the object from S3
try:
    obj = s3.get_object(Bucket=bucket_name, Key=object_key)
except Exception as e:
    print(f"Error fetching object from S3: {e}")
    raise

# Load the CSV data into a DataFrame with dtype specification
try:
    data = pd.read_csv(obj['Body'], dtype={'patient_id': str, 'month_year': str}, low_memory=False)
except Exception as e:
    print(f"Error reading CSV data: {e}")
    raise

# Validate required columns
required_columns = ['patient_id', 'month_year']
for column in required_columns:
    if column not in data.columns:
        raise ValueError(f"Missing required column: {column}")

# Ensure unique index for conversion
data.reset_index(drop=True, inplace=True)

# Convert 'month_year' column to datetime
try:
    data['month_year'] = pd.to_datetime(data['month_year'], errors='coerce')
except Exception as e:
    print(f"Error converting 'month_year' to datetime: {e}")
    raise

# Drop rows with NaT in 'month_year' column
data = data.dropna(subset=['month_year'])

# Group by patient_id and calculate min and max dates
try:
    result = data.groupby('patient_id')['month_year'].agg(['min', 'max']).reset_index()
    result.columns = ['Patient_id', 'enrollment_start_date', 'enrollment_end_date']
except Exception as e:
    print(f"Error during groupby and aggregation: {e}")
    raise

# Count the number of rows
count = len(result)

# Define the full file path
result_file = os.path.join(os.getcwd(), 'patient_enrollment_span.csv')

# Save the result to a CSV file
try:
    print(f"Current working directory before saving: {os.getcwd()}")
    result.to_csv(result_file, index=False)
    print(f"File '{result_file}' saved successfully.")
except Exception as e:
    print(f"Error saving file '{result_file}': {e}")
    raise

# Check if the file exists before uploading
if os.path.exists(result_file):
    print(f"Current working directory before uploading: {os.getcwd()}")
    # Upload the file to S3
    try:
        s3.upload_file(result_file, bucket_name, 'patient_enrollment_span.csv')
        print(f"File '{result_file}' uploaded to bucket '{bucket_name}'.")
    except Exception as e:
        print(f"Error uploading file to S3: {e}")
else:
    print(f"File '{result_file}' does not exist. Unable to upload.")

print(result)
print(f"Number of rows: {count}")